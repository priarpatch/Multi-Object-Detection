{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from utils.dataloader import PascalVOCDataset\n",
    "from utils.dataloader import myimshow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.PositionSensitiveScoreMap import PositionSensitiveScoreMap\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_dir = \"/datasets/ee285f-public/PascalVOC2012/\"\n",
    "# dataset_root_dir = \"../Datasets/VOCtrainval_11-May-2012/VOCdevkit/VOC2012\"\n",
    "\n",
    "#Creating training and validation sets. Go to utils/dataloader.py for info on important PascalVOCDataset arguments & attributes\n",
    "train_set = PascalVOCDataset(dataset_root_dir, mode= 'train')\n",
    "val_set = PascalVOCDataset(dataset_root_dir, mode= 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import  absolute_import\n",
    "# though cupy is not used but without this line, it raise errors...\n",
    "import cupy as cp\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch as t\n",
    "from utils.config import opt\n",
    "from model.rfcn_resnet101 import RFCNResnet101\n",
    "from torch.utils import data as data_\n",
    "from trainer import FasterRCNNTrainer\n",
    "from utils import array_tool as at\n",
    "from utils.vis_tool import visdom_bbox\n",
    "from utils.eval_tool import eval_detection_voc\n",
    "\n",
    "# fix for ulimit\n",
    "# https://github.com/pytorch/pytorch/issues/973#issuecomment-346405667\n",
    "import resource\n",
    "\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (20480, rlimit[1]))\n",
    "\n",
    "matplotlib.use('agg')\n",
    "\n",
    "\n",
    "def eval(dataloader, faster_rcnn, test_num=10000):\n",
    "    gt_difficults = False\n",
    "    pred_bboxes, pred_labels, pred_scores = list(), list(), list()\n",
    "    gt_bboxes, gt_labels, gt_difficults = list(), list(), list()\n",
    "    for ii, (imgs, sizes, gt_bboxes_, gt_labels_) in tqdm(enumerate(dataloader)):\n",
    "        pred_bboxes_, pred_labels_, pred_scores_ = faster_rcnn.predict(imgs)\n",
    "        gt_bboxes += list(gt_bboxes_.numpy())\n",
    "        gt_labels += list(gt_labels_.numpy())\n",
    "        pred_bboxes += pred_bboxes_\n",
    "        pred_labels += pred_labels_\n",
    "        pred_scores += pred_scores_\n",
    "        if ii == test_num: break\n",
    "\n",
    "    result = eval_detection_voc(\n",
    "        pred_bboxes, pred_labels, pred_scores,\n",
    "        gt_bboxes, gt_labels, gt_difficults,\n",
    "        use_07_metric=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "def train(train_set, val_set, load_path = False, epochs = 1, lr=1e-3, record_every = 300, lr_decay = 1e-3,test_num=500):\n",
    "\n",
    "    train_dataloader = td.DataLoader(train_set, batch_size = 1, pin_memory = False, shuffle = True)\n",
    "    test_dataloader = td.DataLoader(val_set, batch_size = 1, pin_memory = True)\n",
    "    faster_rcnn = RFCNResnet101().cuda()\n",
    "    print('model construct completed')\n",
    "    trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n",
    "    saved_loss = []\n",
    "    iterations = []\n",
    "    if load_path:\n",
    "        trainer.load(load_path)\n",
    "        print('load pretrained model from %s' % load_path)\n",
    "        state_dict = t.load(load_path)\n",
    "        saved_loss = state_dict['losses']\n",
    "        iterations = state_dict['iterations']\n",
    "        \n",
    "    best_map = 0\n",
    "    lr_ = lr\n",
    "    for epoch in range(epochs):\n",
    "        trainer.reset_meters()\n",
    "        for ii, (img, bbox_, label_, scale) in tqdm(enumerate(train_dataloader)):\n",
    "            scale = at.scalar(scale)\n",
    "            img, bbox, label = img.cuda().float(), bbox_.cuda(), label_.cuda()\n",
    "            losses = trainer.train_step(img, bbox, label, scale)\n",
    "            loss_info = 'Iter {}; Losses: RPN loc {}, RPN cls: {}, ROI loc {}, ROI cls {}, Total:{}'.format(\n",
    "                                                str(ii),\n",
    "                                                \"%.3f\" % losses[0].cpu().data.numpy(),\n",
    "                                                \"%.3f\" % losses[1].cpu().data.numpy(),\n",
    "                                                \"%.3f\" % losses[2].cpu().data.numpy(),\n",
    "                                                \"%.3f\" % losses[3].cpu().data.numpy(),                                \n",
    "                                                \"%.3f\" % losses[4].cpu().data.numpy())\n",
    "            print(loss_info)\n",
    "            if (ii + 1) % record_every == 0:\n",
    "                \n",
    "                iterations.append(ii + 1) \n",
    "                saved_loss.append([losses[0].cpu().item(),losses[1].cpu().item(),\n",
    "                              losses[2].cpu().item(),losses[3].cpu().item(),\n",
    "                              losses[4].cpu().item()])\n",
    "                kwargs = {\"losses\": saved_loss, \"iterations\": iterations}\n",
    "                trainer.save(saved_loss = saved_loss, iterations = iterations)\n",
    "                print(\"new model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/home-02/50/150/prvo/Multi-Object-Detection/model/rfcn_resnet101.py:83: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  nn.init.normal(self.cls_layer.weight.data, 0.0, 0.01)\n",
      "/datasets/home/home-02/50/150/prvo/Multi-Object-Detection/model/rfcn_resnet101.py:87: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  nn.init.normal(self.reg_layer.weight.data, 0.0, 0.01)\n",
      "WARNING:root:Setting up a new session...\n",
      "WARNING:visdom:Without the incoming socket you cannot receive events from the server or register event handlers to your Visdom client.\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model construct completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/home-02/50/150/prvo/Multi-Object-Detection/utils/PositionSensitiveScoreMap_V2.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  scores = self.softmax(F.adaptive_avg_pool2d(pooling_track.float(),(1,1))[:,:])\n",
      "\n",
      "1it [00:00,  2.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0; Losses: RPN loc 2.196, RPN cls: 0.340, ROI loc 8.534, ROI cls 2.994, Total:14.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/home-02/50/150/prvo/Multi-Object-Detection/model/utils/bbox_tools.py:68: RuntimeWarning: overflow encountered in multiply\n",
      "  h = xp.exp(dh) * src_height[:, xp.newaxis]\n",
      "\n",
      "2it [00:01,  1.84it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1; Losses: RPN loc 88.663, RPN cls: 31.089, ROI loc 142.840, ROI cls 2.600, Total:265.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:01,  1.96it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2; Losses: RPN loc 34.476, RPN cls: 52.984, ROI loc 279.405, ROI cls 2.739, Total:369.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:03,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3; Losses: RPN loc 104.092, RPN cls: 98.988, ROI loc 682.364, ROI cls 2.811, Total:888.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/home-02/50/150/prvo/Multi-Object-Detection/model/utils/bbox_tools.py:69: RuntimeWarning: overflow encountered in multiply\n",
      "  w = xp.exp(dw) * src_width[:, xp.newaxis]\n",
      "\n",
      "5it [00:04,  1.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4; Losses: RPN loc 1.375, RPN cls: 47.994, ROI loc 86.882, ROI cls 2.257, Total:138.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:04,  1.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5; Losses: RPN loc 226.017, RPN cls: 133.182, ROI loc 171.451, ROI cls 2.695, Total:533.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [00:06,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6; Losses: RPN loc 1.607, RPN cls: 8.673, ROI loc 28.534, ROI cls 2.162, Total:40.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:08,  1.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7; Losses: RPN loc 13.987, RPN cls: 10.936, ROI loc 114.155, ROI cls 2.181, Total:141.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9it [00:11,  1.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8; Losses: RPN loc 4.109, RPN cls: 6.376, ROI loc 63.828, ROI cls 2.145, Total:76.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:13,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9; Losses: RPN loc 0.544, RPN cls: 0.516, ROI loc 412.442, ROI cls 2.266, Total:415.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [00:15,  1.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10; Losses: RPN loc 1.465, RPN cls: 1.396, ROI loc 283.612, ROI cls 2.252, Total:288.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12it [00:17,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 11; Losses: RPN loc 1.544, RPN cls: 56.077, ROI loc 97.213, ROI cls 2.158, Total:156.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "13it [00:19,  1.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 12; Losses: RPN loc 42.101, RPN cls: 16.315, ROI loc 638.351, ROI cls 2.357, Total:699.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "14it [00:21,  2.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 13; Losses: RPN loc 6.875, RPN cls: 10.673, ROI loc 256.121, ROI cls 2.221, Total:275.890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:28,  3.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 14; Losses: RPN loc 2.078, RPN cls: 5.091, ROI loc 44.846, ROI cls 2.146, Total:54.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "16it [00:34,  4.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 15; Losses: RPN loc 0.787, RPN cls: 0.829, ROI loc 154.555, ROI cls 2.199, Total:158.370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:39,  4.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 16; Losses: RPN loc 0.956, RPN cls: 0.984, ROI loc 82.762, ROI cls 2.172, Total:86.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "18it [00:43,  4.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 17; Losses: RPN loc 5.196, RPN cls: 11.167, ROI loc 199.902, ROI cls 2.239, Total:218.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "19it [00:50,  5.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 18; Losses: RPN loc 0.331, RPN cls: 0.849, ROI loc 12.305, ROI cls 2.131, Total:15.617\n",
      "Iter 19; Losses: RPN loc 2.159, RPN cls: 2.534, ROI loc 165.224, ROI cls 2.243, Total:172.160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "20it [00:59,  6.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [01:04,  6.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20; Losses: RPN loc 0.496, RPN cls: 0.821, ROI loc 17.071, ROI cls 2.135, Total:20.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "22it [01:11,  6.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 21; Losses: RPN loc 1.234, RPN cls: 0.201, ROI loc 23.498, ROI cls 2.146, Total:27.080\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-de3a74f7ddf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mCHANGE\u001b[0m \u001b[0mload_path\u001b[0m \u001b[0mTO\u001b[0m \u001b[0mTHE\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0mTO\u001b[0m \u001b[0mYOUR\u001b[0m \u001b[0mCHECKPOINT\u001b[0m \u001b[0mIF\u001b[0m \u001b[0mYOU\u001b[0m \u001b[0mARE\u001b[0m \u001b[0mRESUMING\u001b[0m \u001b[0mTRAINING\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m\"checkpoints/rfcnBLAHBLAHBLAH\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-2e4f980df081>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_set, val_set, load_path, epochs, lr, record_every, lr_decay, test_num)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             loss_info = 'Iter {}; Losses: RPN loc {}, RPN cls: {}, ROI loc {}, ROI cls {}, Total:{}'.format(\n\u001b[1;32m     73\u001b[0m                                                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-02/50/150/prvo/Multi-Object-Detection/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, imgs, bboxes, labels, scale)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "CHANGE load_path TO THE PATH TO YOUR CHECKPOINT IF YOU ARE RESUMING TRAINING. \"checkpoints/rfcnBLAHBLAHBLAH\"\n",
    "'''\n",
    "train(train_set, val_set, load_path = False, epochs = 1, lr=1e-3, record_every = 300)\n",
    "#train(train_set, val_set, load_path = \"checkpoints/...\", epochs = 3, lr=1e-3, record_every = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This will load the state dict which will allow you to obtain losses'''\n",
    "#state_dict = t.load(\"checkpoints/...\")\n",
    "#saved_losses = state_dict[\"other_info\"][\"saved_loss\"]\n",
    "#iterations = state_dict[\"other_info\"][\"iterations\"]\n",
    "\n",
    "#There are other arguments than other_info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
